{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textsum.summarize import Summarizer\n",
    "\n",
    "summarizer = Summarizer(\n",
    "    #model_name_or_path=\"pszemraj/pegasus-x-large-book_synthsumm\",\n",
    "    #model_name_or_path=\"pszemraj/long-t5-tglobal-base-16384-book-summary\",\n",
    "    model_name_or_path=\"pszemraj/led-large-book-summary\",\n",
    "\tnum_beams=4,\n",
    "    force_cache=True,\n",
    "    min_length=16,\n",
    "    no_repeat_ngram_size=3,\n",
    "    encoder_no_repeat_ngram_size=3,\n",
    "    repetition_penalty=3.5,\n",
    "    early_stopping=True,\n",
    "    #optimum_onnx=True,\n",
    "    compile_model=True\n",
    ")\n",
    "\n",
    "summarizer.model.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html2text\n",
    "from cleantext import clean\n",
    "\n",
    "# Configurar o conversor\n",
    "converter = html2text.HTML2Text()\n",
    "converter.ignore_links = True\n",
    "converter.ignore_images = True\n",
    "converter.ignore_tables = True\n",
    "\n",
    "def cleartext(decoded_html):\n",
    "\ttexto_limpo = converter.handle(decoded_html)\n",
    "\ttexto_limpo = clean(\n",
    "\t\ttexto_limpo,\n",
    "\t\tfix_unicode=True,\n",
    "\t\tto_ascii=False,\n",
    "\t\tlower=False,\n",
    "\t\tno_line_breaks=True,\n",
    "\t\tno_urls=True,\n",
    "\t\tno_emails=True,\n",
    "\t\tno_phone_numbers=True,\n",
    "\t\tno_numbers=False,\n",
    "\t\tno_digits=False,\n",
    "\t\tno_currency_symbols=True,\n",
    "\t\tno_punct=False,  # Defina como True se quiser remover pontuação\n",
    "\t\treplace_with_punct=\"\",\n",
    "\t\treplace_with_url=\"\",\n",
    "\t\treplace_with_email=\"\",\n",
    "\t\treplace_with_phone_number=\"\",\n",
    "\t\treplace_with_number=\"\",\n",
    "\t\treplace_with_digit=\"\",\n",
    "\t\treplace_with_currency_symbol=\"\"\n",
    "\t)\n",
    "\n",
    "\treturn texto_limpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from email.header import decode_header\n",
    "\n",
    "def decode_mime_header(header):\n",
    "    \"\"\"\n",
    "    Decodifica um cabeçalho MIME codificado conforme RFC 2047.\n",
    "\n",
    "    Args:\n",
    "        header (str): O cabeçalho a ser decodificado.\n",
    "\n",
    "    Returns:\n",
    "        str: O cabeçalho decodificado como string Unicode.\n",
    "    \"\"\"\n",
    "    if header is None:\n",
    "        return \"\"\n",
    "    decoded_fragments = decode_header(header)\n",
    "    decoded_string = \"\"\n",
    "    for fragment, encoding in decoded_fragments:\n",
    "        if isinstance(fragment, bytes):\n",
    "            if encoding:\n",
    "                try:\n",
    "                    decoded_string += fragment.decode(encoding, errors='replace')\n",
    "                except Exception:\n",
    "                    decoded_string += fragment.decode('utf-8', errors='replace')\n",
    "            else:\n",
    "                # Se a codificação não for especificada, tenta utf-8\n",
    "                decoded_string += fragment.decode('utf-8', errors='replace')\n",
    "        else:\n",
    "            decoded_string += fragment\n",
    "    return decoded_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from datetime import timedelta\n",
    "from email.utils import parsedate_to_datetime\n",
    "\n",
    "def date_format(date_str):\n",
    "\tif date_str:\n",
    "\t\ttry:\n",
    "\t\t\t# Parse a string de data usando email.utils\n",
    "\t\t\tdate = parsedate_to_datetime(date_str)\n",
    "\t\t\t\n",
    "\t\t\t# Gera um número aleatório de microssegundos para adicionar (entre 0 e 999999)\n",
    "\t\t\trandom_microseconds = random.randint(0, 999999)\n",
    "\t\t\t\n",
    "\t\t\t# Adiciona os microssegundos aleatórios à data\n",
    "\t\t\tdate += timedelta(microseconds=random_microseconds)\n",
    "\t\t\t\n",
    "\t\t\t# Formata a data para ISO 8601 (Aceito pelo DuckDB)\n",
    "\t\t\treturn date.isoformat()\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint(f\"Erro ao converter a data: {e}\")\n",
    "\t\t\treturn None\n",
    "\telse:\n",
    "\t\treturn None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mailbox\n",
    "import chardet\n",
    "\n",
    "# Caminho para o diretório Maildir\n",
    "maildir_path = '/home/jadson/.thunderbird/7xvrd8c3.default-release/ImapMail/outlook.office365.com/Antigos n&AOM-o lidos/'\n",
    "\n",
    "# Abrir o Maildir\n",
    "mbox = mailbox.Maildir(maildir_path, factory=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Conectar ou criar o banco de dados DuckDB\n",
    "conn = duckdb.connect('emails2.duckdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x7f0a4e3f2930>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criar a tabela de e-mails se não existir\n",
    "conn.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS emails (\n",
    "    subject TEXT,\n",
    "    sender TEXT,\n",
    "    body TEXT,\n",
    "    date TIMESTAMP PRIMARY KEY\n",
    ")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 0/22340 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "964367f1798a42168641082e964bbe35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/23/2024 09:49:28 INFO Note: NumExpr detected 20 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "10/23/2024 09:49:28 INFO NumExpr defaulting to 8 threads.\n",
      "Processando Mensagens:   0%|          | 1/22340 [00:09<57:05:06,  9.20s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb0a9cc84fe446ccad1f3cb582cae422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 2/22340 [00:11<31:56:00,  5.15s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3dab79472734b5fa2deeb8abd3538a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 3/22340 [00:12<21:30:51,  3.47s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a155aa40b8684ca6b99cdfb224e96cbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 4/22340 [00:14<17:19:03,  2.79s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54743ad8a57b471e8dc5fb27472a6b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 5/22340 [00:17<17:43:04,  2.86s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dff853ae923f4553b1933ef70db66c65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 6/22340 [00:19<14:26:34,  2.33s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c48b5a5348e40e6b6f51723b34d7a42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 7/22340 [00:23<18:46:02,  3.03s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a2830f0d8254b8d9a593defc8a01dd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 8/22340 [00:27<21:28:03,  3.46s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88f62342eef346edbd499115c5d152ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 9/22340 [00:35<30:06:54,  4.85s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58fda18f9a9f43e8b12c9fd56d806185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 10/22340 [00:38<25:13:18,  4.07s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7200909ea5d441591d3136ff27facf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 11/22340 [00:39<19:53:07,  3.21s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfb9ab8176104460b828b5c22046aa9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 12/22340 [00:43<20:49:20,  3.36s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36b897ae381840cb9c2d34b418302f1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 13/22340 [00:45<19:53:21,  3.21s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7d541bc56714b74b1e5d669019693bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 14/22340 [00:47<17:16:48,  2.79s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1217dc2ab96b4ca5b6397e23e058c76e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 15/22340 [00:54<23:50:15,  3.84s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80d3b28db80b4db98910262c07564dbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 16/22340 [01:00<28:02:09,  4.52s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cce2b1aae8d4a43beb649ecf5f107dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 17/22340 [01:03<25:16:12,  4.08s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebdda18f15934f9c8284a45119d56470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 18/22340 [01:05<21:14:11,  3.42s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48d969a75d80415b9dcdd23808730cac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 19/22340 [01:07<19:32:25,  3.15s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c53bc705fa14dab8ea8e0bf6b074eaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 20/22340 [01:11<21:18:57,  3.44s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca424e5ab65346709d69c46745fe0c17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 21/22340 [01:15<21:20:25,  3.44s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e164f5db667b43e6b17472927556dbe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 22/22340 [01:16<17:14:36,  2.78s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f18ac9d4cddb4594a7b533228da1f24e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 23/22340 [01:17<14:24:43,  2.32s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6704760af25403d9ea2f5bdfcdca5a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 24/22340 [01:27<27:44:48,  4.48s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31821c00ecf34feb8d5eabe8c6edbebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 25/22340 [01:32<30:04:44,  4.85s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d47ef37b24b4f0292d859459bc7a035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 26/22340 [01:39<33:14:55,  5.36s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a0a80ab062c4e818c797623269975dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 27/22340 [01:46<36:44:25,  5.93s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf5f5810624f4af7a884499f761bec03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 28/22340 [01:53<37:51:33,  6.11s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fd412d2acf847fe98df9ccd0ab7e534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 29/22340 [01:54<28:34:38,  4.61s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9384da17b2c84e7cb41cbcb8db76cf52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 30/22340 [02:00<32:18:36,  5.21s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dbefba7564c4ace80eeaf27de7036c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 31/22340 [02:06<33:54:25,  5.47s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "557adacce0c2429a8b7005c861a5b4f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 32/22340 [02:08<27:20:09,  4.41s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36f52a47350746a9866f5773cd1d6abd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 33/22340 [02:10<21:32:07,  3.48s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b5c5a1547f149e6bcbd7b13aa9ad289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 34/22340 [02:11<17:09:17,  2.77s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bac420561fdc47739f6ad3f0c0e9ba04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 35/22340 [02:12<14:25:11,  2.33s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c687b5e6984457e99bd38ab99098b08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 36/22340 [02:18<21:42:12,  3.50s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f0f4c523f8d43c9921bbc9f56d2520c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 37/22340 [02:24<25:46:00,  4.16s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d7a4752b424421595546bfdc4f60a46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 38/22340 [02:35<37:48:00,  6.10s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d89165bd50d4d33945ecce6f8907907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 39/22340 [02:43<41:57:18,  6.77s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c2de53ba8f143c3be4ecad8123dd551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 40/22340 [02:47<36:09:41,  5.84s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea23b9c5b3a74ff8b567206025996de0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 41/22340 [02:50<31:57:19,  5.16s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "071ee61e29e04fffbe0c4fa7c6d417da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 42/22340 [02:51<23:55:40,  3.86s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e614322dd40c4c7b95faddea8eeef2bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 43/22340 [02:54<22:46:26,  3.68s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27d36f9309254186bc2384cd6aaf8a7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 44/22340 [03:04<33:04:46,  5.34s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77f32f8ed9934420a7f5ae9c1a5eaa99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 45/22340 [03:10<34:12:31,  5.52s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f91835572d544f32833b41c942e02e24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 46/22340 [03:16<36:10:39,  5.84s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "316046bd3b5142438401cb6856b7336d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 47/22340 [03:24<39:41:59,  6.41s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de9ff2c7f25445d68d808894a8120f47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 48/22340 [03:27<34:15:08,  5.53s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7648e138c05c4c1dae49c20bf5d0dd48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 49/22340 [03:31<30:52:14,  4.99s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "590944d68ac44ee49e3efd0e8584a42f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 50/22340 [03:35<28:13:11,  4.56s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4f00fe41c1443838b5c735d206a6fe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 51/22340 [03:36<22:43:24,  3.67s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cd6217579af48deaf97d9ba991001d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 52/22340 [03:51<44:00:03,  7.11s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1d346d53a174310b2c92563ef5fc972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 53/22340 [03:55<37:01:24,  5.98s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f1e50e1ca624eb7b023d53e7133c4c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 54/22340 [03:58<32:12:23,  5.20s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65b7f4e0ab134aaca304913f411b2b4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 55/22340 [04:02<30:27:42,  4.92s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08d3a17dedfa485fb9912c971a15b4cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 56/22340 [04:08<32:02:33,  5.18s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dce7263b481a4f0eb482044ad80ea986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Mensagens:   0%|          | 56/22340 [04:11<27:49:31,  4.50s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 50\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     48\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mErro ao decodificar a mensagem: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 50\u001b[0m content \u001b[38;5;241m=\u001b[39m summarizer\u001b[38;5;241m.\u001b[39msummarize_string(body)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Inserir os dados no DuckDB\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/textsum/summarize.py:506\u001b[0m, in \u001b[0;36mSummarizer.summarize_string\u001b[0;34m(self, input_text, batch_length, batch_stride, batch_delimiter, disable_progress_bar, **kwargs)\u001b[0m\n\u001b[1;32m    500\u001b[0m     batch_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m512\u001b[39m\n\u001b[1;32m    502\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_length: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m batch_stride: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_stride\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, kwargs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m )\n\u001b[0;32m--> 506\u001b[0m gen_summaries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msummarize_via_tokenbatches(\n\u001b[1;32m    507\u001b[0m     input_text,\n\u001b[1;32m    508\u001b[0m     batch_length\u001b[38;5;241m=\u001b[39mbatch_length,\n\u001b[1;32m    509\u001b[0m     batch_stride\u001b[38;5;241m=\u001b[39mbatch_stride,\n\u001b[1;32m    510\u001b[0m     disable_progress_bar\u001b[38;5;241m=\u001b[39mdisable_progress_bar,\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    512\u001b[0m )\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_summary(\n\u001b[1;32m    515\u001b[0m     summary_data\u001b[38;5;241m=\u001b[39mgen_summaries,\n\u001b[1;32m    516\u001b[0m     return_string\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    517\u001b[0m     batch_delimiter\u001b[38;5;241m=\u001b[39mbatch_delimiter,\n\u001b[1;32m    518\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/textsum/summarize.py:380\u001b[0m, in \u001b[0;36mSummarizer.summarize_via_tokenbatches\u001b[0;34m(self, input_text, batch_length, batch_stride, min_batch_length, pad_incomplete_batch, disable_progress_bar, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m     _id \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([_id, torch\u001b[38;5;241m.\u001b[39mtensor([pad_token] \u001b[38;5;241m*\u001b[39m difference)])\n\u001b[1;32m    378\u001b[0m     _mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([_mask, torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m difference)])\n\u001b[0;32m--> 380\u001b[0m result, score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msummarize_and_score(\n\u001b[1;32m    381\u001b[0m     ids\u001b[38;5;241m=\u001b[39m_id,\n\u001b[1;32m    382\u001b[0m     mask\u001b[38;5;241m=\u001b[39m_mask,\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    384\u001b[0m )\n\u001b[1;32m    385\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mfloat\u001b[39m(score), \u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m    386\u001b[0m _sum \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: _id,\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m\"\u001b[39m: result,\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary_score\u001b[39m\u001b[38;5;124m\"\u001b[39m: score,\n\u001b[1;32m    390\u001b[0m }\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/textsum/summarize.py:277\u001b[0m, in \u001b[0;36mSummarizer.summarize_and_score\u001b[0;34m(self, ids, mask, autocast_enabled, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautocast(device_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice, enabled\u001b[38;5;241m=\u001b[39mautocast_enabled):\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_general_attention_model:\n\u001b[0;32m--> 277\u001b[0m         summary_pred_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m    278\u001b[0m             input_ids,\n\u001b[1;32m    279\u001b[0m             attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m    280\u001b[0m             output_scores\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    281\u001b[0m             return_dict_in_generate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    282\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    283\u001b[0m         )\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    285\u001b[0m         \u001b[38;5;66;03m# this is for LED etc.\u001b[39;00m\n\u001b[1;32m    286\u001b[0m         summary_pred_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m    287\u001b[0m             input_ids,\n\u001b[1;32m    288\u001b[0m             attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    293\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/generation/utils.py:2078\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2070\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2071\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2072\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   2073\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2074\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2075\u001b[0m     )\n\u001b[1;32m   2077\u001b[0m     \u001b[38;5;66;03m# 13. run beam sample\u001b[39;00m\n\u001b[0;32m-> 2078\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_beam_search(\n\u001b[1;32m   2079\u001b[0m         input_ids,\n\u001b[1;32m   2080\u001b[0m         beam_scorer,\n\u001b[1;32m   2081\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[1;32m   2082\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[1;32m   2083\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[1;32m   2084\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[1;32m   2085\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2086\u001b[0m     )\n\u001b[1;32m   2088\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGROUP_BEAM_SEARCH:\n\u001b[1;32m   2089\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2090\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2091\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2092\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2098\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2099\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/generation/utils.py:3253\u001b[0m, in \u001b[0;36mGenerationMixin._beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   3250\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m stack_model_outputs(outputs_per_sub_batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget_text_config())\n\u001b[1;32m   3252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Unchanged original behavior\u001b[39;00m\n\u001b[0;32m-> 3253\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   3255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   3256\u001b[0m     cur_len \u001b[38;5;241m=\u001b[39m cur_len \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/models/led/modeling_led.py:2398\u001b[0m, in \u001b[0;36mLEDForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, global_attention_mask, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   2393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m decoder_input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m decoder_inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2394\u001b[0m         decoder_input_ids \u001b[38;5;241m=\u001b[39m shift_tokens_right(\n\u001b[1;32m   2395\u001b[0m             labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdecoder_start_token_id\n\u001b[1;32m   2396\u001b[0m         )\n\u001b[0;32m-> 2398\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mled(\n\u001b[1;32m   2399\u001b[0m     input_ids,\n\u001b[1;32m   2400\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m   2401\u001b[0m     decoder_input_ids\u001b[38;5;241m=\u001b[39mdecoder_input_ids,\n\u001b[1;32m   2402\u001b[0m     decoder_attention_mask\u001b[38;5;241m=\u001b[39mdecoder_attention_mask,\n\u001b[1;32m   2403\u001b[0m     encoder_outputs\u001b[38;5;241m=\u001b[39mencoder_outputs,\n\u001b[1;32m   2404\u001b[0m     global_attention_mask\u001b[38;5;241m=\u001b[39mglobal_attention_mask,\n\u001b[1;32m   2405\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[1;32m   2406\u001b[0m     decoder_head_mask\u001b[38;5;241m=\u001b[39mdecoder_head_mask,\n\u001b[1;32m   2407\u001b[0m     cross_attn_head_mask\u001b[38;5;241m=\u001b[39mcross_attn_head_mask,\n\u001b[1;32m   2408\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[1;32m   2409\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[1;32m   2410\u001b[0m     decoder_inputs_embeds\u001b[38;5;241m=\u001b[39mdecoder_inputs_embeds,\n\u001b[1;32m   2411\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m   2412\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   2413\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m   2414\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m   2415\u001b[0m )\n\u001b[1;32m   2416\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(outputs[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_logits_bias\n\u001b[1;32m   2418\u001b[0m masked_lm_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/models/led/modeling_led.py:2268\u001b[0m, in \u001b[0;36mLEDModel.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, global_attention_mask, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   2260\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m LEDEncoderBaseModelOutput(\n\u001b[1;32m   2261\u001b[0m         last_hidden_state\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m   2262\u001b[0m         hidden_states\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2263\u001b[0m         attentions\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2264\u001b[0m         global_attentions\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2265\u001b[0m     )\n\u001b[1;32m   2267\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 2268\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(\n\u001b[1;32m   2269\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39mdecoder_input_ids,\n\u001b[1;32m   2270\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mdecoder_attention_mask,\n\u001b[1;32m   2271\u001b[0m     encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m   2272\u001b[0m     encoder_attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m   2273\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mdecoder_head_mask,\n\u001b[1;32m   2274\u001b[0m     cross_attn_head_mask\u001b[38;5;241m=\u001b[39mcross_attn_head_mask,\n\u001b[1;32m   2275\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[1;32m   2276\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39mdecoder_inputs_embeds,\n\u001b[1;32m   2277\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m   2278\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   2279\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m   2280\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m   2281\u001b[0m )\n\u001b[1;32m   2283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[1;32m   2284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decoder_outputs \u001b[38;5;241m+\u001b[39m encoder_outputs\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/models/led/modeling_led.py:2131\u001b[0m, in \u001b[0;36mLEDDecoder.forward\u001b[0;34m(self, input_ids, attention_mask, global_attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   2118\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   2119\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m   2120\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2128\u001b[0m         use_cache,\n\u001b[1;32m   2129\u001b[0m     )\n\u001b[1;32m   2130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2131\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m decoder_layer(\n\u001b[1;32m   2132\u001b[0m         hidden_states,\n\u001b[1;32m   2133\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mcombined_attention_mask,\n\u001b[1;32m   2134\u001b[0m         encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[1;32m   2135\u001b[0m         encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_attention_mask,\n\u001b[1;32m   2136\u001b[0m         layer_head_mask\u001b[38;5;241m=\u001b[39m(head_mask[idx] \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   2137\u001b[0m         cross_attn_layer_head_mask\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   2138\u001b[0m             cross_attn_head_mask[idx] \u001b[38;5;28;01mif\u001b[39;00m cross_attn_head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2139\u001b[0m         ),\n\u001b[1;32m   2140\u001b[0m         past_key_value\u001b[38;5;241m=\u001b[39mpast_key_value,\n\u001b[1;32m   2141\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   2142\u001b[0m         use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m   2143\u001b[0m     )\n\u001b[1;32m   2145\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   2147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/models/led/modeling_led.py:1063\u001b[0m, in \u001b[0;36mLEDDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# cross_attn cached key/values tuple is at positions 3,4 of present_key_value tuple\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m cross_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1063\u001b[0m hidden_states, cross_attn_weights, cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_attn(\n\u001b[1;32m   1064\u001b[0m     hidden_states\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[1;32m   1065\u001b[0m     key_value_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[1;32m   1066\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mencoder_attention_mask,\n\u001b[1;32m   1067\u001b[0m     layer_head_mask\u001b[38;5;241m=\u001b[39mcross_attn_layer_head_mask,\n\u001b[1;32m   1068\u001b[0m     past_key_value\u001b[38;5;241m=\u001b[39mcross_attn_past_key_value,\n\u001b[1;32m   1069\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   1070\u001b[0m )\n\u001b[1;32m   1071\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(hidden_states, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[1;32m   1072\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/models/led/modeling_led.py:915\u001b[0m, in \u001b[0;36mLEDDecoderAttention.forward\u001b[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    904\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`attn_output` should be of size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(bsz,\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\u001b[38;5;250m \u001b[39mtgt_len,\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but is\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    906\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattn_output\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    907\u001b[0m     )\n\u001b[1;32m    909\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    910\u001b[0m     attn_output\u001b[38;5;241m.\u001b[39mview(bsz, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, tgt_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\n\u001b[1;32m    911\u001b[0m     \u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    912\u001b[0m     \u001b[38;5;241m.\u001b[39mreshape(bsz, tgt_len, embed_dim)\n\u001b[1;32m    913\u001b[0m )\n\u001b[0;32m--> 915\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_proj(attn_output)\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m attn_output, attn_weights_reshaped, past_key_value\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1716\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m   1709\u001b[0m \u001b[38;5;66;03m# On the return type:\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;66;03m# We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;66;03m# This is done for better interop with various type checkers for the end users.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1714\u001b[0m \u001b[38;5;66;03m# See full discussion on the problems with returning `Union` here\u001b[39;00m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;66;03m# https://github.com/microsoft/pyright/issues/4213\u001b[39;00m\n\u001b[0;32m-> 1716\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1717\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1718\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Iterar sobre as mensagens\n",
    "for idx, message in enumerate(tqdm(mbox, desc=\"Processando Mensagens\"), 1):\n",
    "    subject = decode_mime_header(message['subject'])\n",
    "    sender = decode_mime_header(message['from'])\n",
    "    \n",
    "\t# Obter a data do e-mail, se disponível\n",
    "    date = date_format(message.get('date'))\n",
    "    \n",
    "    body = ''\n",
    "\n",
    "    if message.is_multipart():\n",
    "        for part in message.walk():\n",
    "            content_type = part.get_content_type()\n",
    "            if content_type == 'text/plain':\n",
    "                payload = part.get_payload(decode=True)\n",
    "                if payload:\n",
    "                    # Detectar a codificação usando chardet\n",
    "                    result = chardet.detect(payload)\n",
    "                    encoding = result['encoding'] if result['encoding'] else 'utf-8'\n",
    "                    try:\n",
    "                        decoded_text = payload.decode(encoding, errors='replace')\n",
    "                        body += cleartext(decoded_text)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Erro ao decodificar a parte da mensagem: {e}\")\n",
    "            elif content_type == 'text/html':\n",
    "                payload = part.get_payload(decode=True)\n",
    "                if payload:\n",
    "                    # Detectar a codificação usando chardet\n",
    "                    result = chardet.detect(payload)\n",
    "                    encoding = result['encoding'] if result['encoding'] else 'utf-8'\n",
    "                    try:\n",
    "                        decoded_html = payload.decode(encoding, errors='replace')\n",
    "                        # Converter HTML para texto usando html2text\n",
    "                        converted_text = cleartext(decoded_html)\n",
    "                        body += converted_text\n",
    "                    except Exception as e:\n",
    "                        print(f\"Erro ao converter HTML da mensagem: {e}\")\n",
    "    else:\n",
    "        payload = message.get_payload(decode=True)\n",
    "        if payload:\n",
    "            # Detectar a codificação usando chardet\n",
    "            result = chardet.detect(payload)\n",
    "            encoding = result['encoding'] if result['encoding'] else 'utf-8'\n",
    "            try:\n",
    "                decoded_text = payload.decode(encoding, errors='replace')\n",
    "                body += cleartext(decoded_text)\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao decodificar a mensagem: {e}\")\n",
    "\n",
    "    content = summarizer.summarize_string(body)\n",
    "    \n",
    "    # Inserir os dados no DuckDB\n",
    "    try:\n",
    "        conn.execute(\"\"\"\n",
    "        INSERT INTO emails (subject, sender, body, date)\n",
    "        VALUES (?, ?, ?, ?)\n",
    "        \"\"\", (subject, sender, content, date))\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao inserir dados no DuckDB: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fechar a conexão com o banco de dados\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
